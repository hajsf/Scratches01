<!doctype html>
<html class="js-focus-visible"><head>
    <title>My App title</title>
    <!-- Important to load artyom in the head tag, this give time to load all the voices in the browser -->

       <script type="text/javascript">
       // Example POST method implementation:
        async function postData(url = '', data = {}) {
          // Default options are marked with *
          const response = await fetch(url, {
            method: 'POST', // *GET, POST, PUT, DELETE, etc.
            mode: 'cors', // no-cors, *cors, same-origin
            cache: 'no-cache', // *default, no-cache, reload, force-cache, only-if-cached
            credentials: 'same-origin', // include, *same-origin, omit
            headers: {
              'Content-Type': 'application/json'
              // 'Content-Type': 'application/x-www-form-urlencoded',
            },
            redirect: 'follow', // manual, *follow, error
            referrerPolicy: 'no-referrer', // no-referrer, *no-referrer-when-downgrade, origin, origin-when-cross-origin, same-origin, strict-origin, strict-origin-when-cross-origin, unsafe-url
            body: JSON.stringify(data) // body data type must match "Content-Type" header
          });
          return response.json(); // parses JSON response into native JavaScript objects
        }
        function post(){ 
         /*   postData('http://localhost:8000/message/4', { id: 4, contents: 'answer 2' })
              .then(response => {
                  console.log(response);
              });   */
              postData('http://localhost:8000/invoke/', { command: 'What is 1 / 2' })
              .then(response => {
                  console.log(response);
              });
        }

       window.onbeforeunload = function () {
            return "Do you really want to close?";
        };

          function LogOff() {
            alert("bye");
           }
   /*     window.addEventListener("beforeunload", function (e) {
            e.preventDefault();
            e.returnValue = '';

          var confirmationMessage = "\o/";

          (e || window.event).returnValue = confirmationMessage; //Gecko + IE
          return confirmationMessage;                            //Webkit, Safari, Chrome
        });  */
    </script>

<script>

    // text to Speech
            // list of languages is probably not loaded, wait for it
        if(window.speechSynthesis.getVoices().length == 0) {
            window.speechSynthesis.addEventListener('voiceschanged', function() {
                textToSpeech();
            });
        }
        else {
            // languages list available, no need to wait
            textToSpeech()
        }

        function textToSpeech(msg) {
            // get all voices that browser offers
            var available_voices = window.speechSynthesis.getVoices();

            // this will hold an english voice
            var english_voice = '';

            // find voice by language locale "en-US"
            // if not then select the first voice
            for(var i=0; i<available_voices.length; i++) {
                if(available_voices[i].lang === 'en-US') {
                    english_voice = available_voices[i];
                    break;
                }
            }
            if(english_voice === '')
                english_voice = available_voices[0];

            // new SpeechSynthesisUtterance object
            var utter = new SpeechSynthesisUtterance();
            utter.rate = 1;
            utter.pitch = 0.5;
            utter.text = msg;
            utter.voice = english_voice;

            // event after text has been spoken
            utter.onend = function() {
             //   alert('Speech has finished');
            }

            // speak
            window.speechSynthesis.speak(utter);
        }


    // Spech Recognition
        if (!('webkitSpeechRecognition' in window) && !('SpeechRecognitionn' in window)) {
                alert("not supported");
                console.log("Speech API not supported hereâ€¦");
        } else { //Letâ€™s do some cool stuff :)
            alert("supported");
            var recognition = new webkitSpeechRecognition(); //That is the object that will manage our whole recognition process.
            recognition.continuous = true;   //Suitable for dictation.
            recognition.interimResults = true;  //If we want to start receiving results even if they are not final.
            //Define some more additional parameters for the recognition:
            recognition.lang = "en-US";
            recognition.maxAlternatives = 1; //Since from our experience, the highest result is really the best...
            recognition.start();
        }

        recognition.onstart = function() {
            console.log("I'm listening");
        };

        recognition.onend = function() {
            console.log("stopped/ended");
            recognition.start();
        };

        recognition.onresult = function(event) { //the event holds the results
            if (typeof(event.results) === 'undefined') { //Something is wrongâ€¦
                recognition.stop();
                return;
            }

            for (var i = event.resultIndex; i < event.results.length; ++i) {
                document.querySelector("#demo").innerHTML = event.results[i][0].transcript;
                if (event.results[i].isFinal) { //Final results
               //     document.querySelector('#button').click(event.results[i][0].transcript);
                    var msg = new SpeechSynthesisUtterance(event.results[i][0].transcript);
                    window.speechSynthesis.speak(msg);
                    // document.querySelector("#demo").innerHTML = event.results[i][0].transcript;
                    console.log("final results: " + event.results[i][0].transcript);   //Of course â€“ here is the place to do useful things with the results.
                } else {   //i.e. interim...
                    console.log("interim results: " + event.results[i][0].transcript);  //You can use these results to give the user near real time experience.
                }
            } //end for loop
        };

    function startButton(event) {
        recognition.start();
        start_img.src = 'https://speechlogger.appspot.com/images/micslash2.png'; //We change the image to a slashed until the user approves the browser to listen and recognition actually starts. Then â€“ weâ€™ll change the image to â€˜mic onâ€™.
    }

    function welcome(event){
        textToSpeech(event);
    }
</script>

</head>
  <body onUnload="LogOff()">
       <div onclick="startButton(event);"><img alt="Start" id="start_img" src="https://speechlogger.appspot.com/images/micoff2.png"></div>
      <div id="demo"> hello</div>
       <button id="button" onclick="post();">test</button>

  <script>
  //  document.querySelector('#button').click();


  </script>


</body><loom-container id="lo-engage-ext-container"><div></div><loom-shadow classname="resolved"></loom-shadow></loom-container></html>